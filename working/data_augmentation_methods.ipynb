{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statutory-throat",
   "metadata": {},
   "source": [
    "# LwTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modular-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "# LwTR - Label-wise Token Replacement\n",
    "def lwtr(train_file):\n",
    "    \n",
    "    lwtr_file = train_file.copy() #make new list to prevent overwritting original file-list\n",
    "    \n",
    "    #for Label-wise Token Replacement, we need to catalogue each possible label\n",
    "    o_label = [line for line in file if ' _ _ O' in line]\n",
    "    b_prod = [line for line in file if ' _ _ B-PROD' in line]\n",
    "    b_grp = [line for line in file if ' _ _ B-GRP' in line]\n",
    "    b_corp = [line for line in file if ' _ _ B-CORP' in line]\n",
    "    b_cw = [line for line in file if ' _ _ B-CW' in line]\n",
    "    b_per = [line for line in file if ' _ _ B-PER' in line]\n",
    "    b_loc = [line for line in file if ' _ _ B-LOC' in line]\n",
    "    i_prod = [line for line in file if ' _ _ I-PROD' in line]\n",
    "    i_grp = [line for line in file if ' _ _ I-GRP' in line]\n",
    "    i_corp = [line for line in file if ' _ _ I-CORP' in line]\n",
    "    i_cw = [line for line in file if ' _ _ I-CW' in line]\n",
    "    i_per = [line for line in file if ' _ _ I-PER' in line]\n",
    "    i_loc = [line for line in file if ' _ _ I-LOC' in line]\n",
    "\n",
    "    #dictionary of labels\n",
    "    lwtr = {'O': o_label, \n",
    "            'B-PROD': b_prod,\n",
    "            'B-GRP': b_grp,\n",
    "            'B-CORP': b_corp,\n",
    "            'B-CW': b_cw,\n",
    "            'B-PER': b_per,\n",
    "            'B-LOC': b_loc,\n",
    "            'I-PROD': i_prod,\n",
    "            'I-GRP': i_grp,\n",
    "            'I-CORP': i_corp,\n",
    "            'I-CW': i_cw,\n",
    "            'I-PER': i_per,\n",
    "            'I-LOC': i_loc}\n",
    "\n",
    "    for index, line in enumerate(train_file): #traverse through file. index:value\n",
    "        x = random.binomial(n=1, p=0.5, size=1) #randomizer. x will be 0 or 1\n",
    "        #x==1 means successly random / startswith() is to filter out id lines / line.strip() is to filter out '\\n' lines\n",
    "        if x == 1 and not line.startswith('# id ') and line.strip(): \n",
    "            curr_label = line.split(' _ _ ')[1].strip() #label found in current line. will be used as the key for lwtr dict\n",
    "            lwtr_file[index] = random.choice(lwtr[curr_label]) #access lwtr dict to randomly choose replacement token of same label and reassign it to current line in file\n",
    "    \n",
    "    return lwtr_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "meaningful-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/BN-Bangla/bn_train_sr.conll') as f:\n",
    "    file = [i for i in f.readlines()]\n",
    "part2 = lwtr(train_file = file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-history",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-indiana",
   "metadata": {},
   "source": [
    "# SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "editorial-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_replace(train_file, word_vector):\n",
    "    from numpy import random\n",
    "    from gensim.test.utils import datapath\n",
    "    from gensim.models.fasttext import load_facebook_vectors\n",
    "    \n",
    "    wv = load_facebook_vectors(word_vector) #load language word vector\n",
    "    \n",
    "    sr_file = [] #eventual file to write into .conll \n",
    "    aug_count = 0\n",
    "    no_aug_count = 0\n",
    "    for index, line in enumerate(file):\n",
    "        if not line.startswith('# id ') and line.strip(): #filter out '#id' and '\\n'\n",
    "            x = random.binomial(n=1, p=0.5, size=1) #random coin flip, 1 is augment, 0 is no augmentation\n",
    "            if x == 1: #augment by replacing current word with the most similar (synonym) word in word vector\n",
    "                separate = line.split(' _ _ ') #to get a list of just the word with the label\n",
    "                word = separate[0] #isolate the word in the line, without it's label\n",
    "                synonym = wv.most_similar(word)[0][0] #synonym of isolated word. 'most_similar' returns list of most top 10 most similar words, with corresponding percentage likelihoods. we just need the MOST likely ([0]), without the percentage ([0])\n",
    "                separate[0] = synonym #replace original word with its new synonym\n",
    "                sr_file.append(' _ _ '.join(separate)) #join back together in format of 'synonym _ _ label'\n",
    "                \n",
    "                aug_count += 1\n",
    "                \n",
    "            else: #no augmentation, still keep original line\n",
    "                sr_file.append(line)\n",
    "                \n",
    "                no_aug_count += 1\n",
    "        else: #append #id's and \\n\n",
    "            sr_file.append(line)\n",
    "    print(f'{aug_count} instances of synonym replacement.')\n",
    "    print(f'{no_aug_count} instances of no synonym replacement.')\n",
    "    return sr_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "altered-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109212 instances of synonym replacement.\n",
      "109187 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Turkish\n",
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/TR-Turkish/wiki.tr/wiki.tr.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "guided-momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191503 instances of synonym replacement.\n",
      "190646 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Chinese\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ZH-Chinese/wiki.zh/wiki.zh.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "killing-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121800 instances of synonym replacement.\n",
      "122766 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Hindi\n",
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/HI-Hindi/wiki.hi/wiki.hi.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "incoming-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139284 instances of synonym replacement.\n",
      "138963 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Farsi\n",
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/FA-Farsi/wiki.fa/wiki.fa.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "oriented-wesley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109305 instances of synonym replacement.\n",
      "109417 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#German\n",
    "with open('SemEval2022-Task11_Train-Dev/DE-German/de_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/DE-German/wiki.de/wiki.de.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/DE-German/de_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "central-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121102 instances of synonym replacement.\n",
      "121282 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Russian\n",
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/RU-Russian/wiki.ru/wiki.ru.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "academic-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116538 instances of synonym replacement.\n",
      "116935 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Dutch\n",
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/NL-Dutch/wiki.nl/wiki.nl.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "numerical-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132922 instances of synonym replacement.\n",
      "133813 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#Spanish\n",
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ES-Spanish/wiki.es/wiki.es.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "level-produce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126980 instances of synonym replacement.\n",
      "126559 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "#English\n",
    "with open('SemEval2022-Task11_Train-Dev/EN-English/en_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/EN-English/wiki.en/wiki.en.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/EN-English/en_train_sr.conll', 'w') as file:\n",
    "    for line in sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "coastal-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-authority",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lesser-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126943 instances of synonym replacement.\n",
      "126596 instances of no synonym replacement.\n"
     ]
    }
   ],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/EN-English/en_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "a = syn_replace(file, 'SemEval2022-Task11_Train-Dev/EN-English/wiki.en/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indonesian-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133461 instances of synonym replacement.\n",
      "133274 instances of no synonym replacement.\n",
      "29024 instances of shuffling.\n",
      "28941 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Spanish\n",
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "es_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ES-Spanish/wiki.es/wiki.es.bin')\n",
    "\n",
    "es_mr = mr(file = es_sr)\n",
    "\n",
    "all_methods = shuffle(file = es_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "es_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ES-Spanish/wiki.es/wiki.es.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ES-Spanish/es_train_sr.conll', 'w') as file:\n",
    "    for line in es_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "narrative-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139155 instances of synonym replacement.\n",
      "139092 instances of no synonym replacement.\n",
      "27716 instances of shuffling.\n",
      "27751 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Farsi\n",
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "fa_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/FA-Farsi/wiki.fa/wiki.fa.bin')\n",
    "\n",
    "fa_mr = mr(file = fa_sr)\n",
    "\n",
    "all_methods = shuffle(file = fa_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "fa_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/FA-Farsi/wiki.fa/wiki.fa.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/FA-Farsi/fa_train_sr.conll', 'w') as file:\n",
    "    for line in fa_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "equal-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122031 instances of synonym replacement.\n",
      "122535 instances of no synonym replacement.\n",
      "21758 instances of shuffling.\n",
      "22129 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Hindi\n",
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "hi_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/HI-Hindi/wiki.hi/wiki.hi.bin')\n",
    "\n",
    "hi_mr = mr(file = hi_sr)\n",
    "\n",
    "all_methods = shuffle(file = hi_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "hi_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/HI-Hindi/wiki.hi/wiki.hi.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/HI-Hindi/hi_train_sr.conll', 'w') as file:\n",
    "    for line in hi_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unique-windsor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116738 instances of synonym replacement.\n",
      "116735 instances of no synonym replacement.\n",
      "28789 instances of shuffling.\n",
      "29110 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Dutch\n",
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "nl_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/NL-Dutch/wiki.nl/wiki.nl.bin')\n",
    "\n",
    "nl_mr = mr(file = nl_sr)\n",
    "\n",
    "all_methods = shuffle(file = nl_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "nl_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/NL-Dutch/wiki.nl/wiki.nl.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/NL-Dutch/nl_train_sr.conll', 'w') as file:\n",
    "    for line in nl_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "republican-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121204 instances of synonym replacement.\n",
      "121180 instances of no synonym replacement.\n",
      "26139 instances of shuffling.\n",
      "26035 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Russian\n",
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "ru_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/RU-Russian/wiki.ru/wiki.ru.bin')\n",
    "\n",
    "ru_mr = mr(file = ru_sr)\n",
    "\n",
    "all_methods = shuffle(file = ru_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "ru_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/RU-Russian/wiki.ru/wiki.ru.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/RU-Russian/ru_train_sr.conll', 'w') as file:\n",
    "    for line in ru_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "amended-mineral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109387 instances of synonym replacement.\n",
      "109012 instances of no synonym replacement.\n",
      "28877 instances of shuffling.\n",
      "28991 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Turkish\n",
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "tr_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/TR-Turkish/wiki.tr/wiki.tr.bin')\n",
    "\n",
    "tr_mr = mr(file = tr_sr)\n",
    "\n",
    "all_methods = shuffle(file = tr_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "tr_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/TR-Turkish/wiki.tr/wiki.tr.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/TR-Turkish/tr_train_sr.conll', 'w') as file:\n",
    "    for line in tr_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "champion-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190279 instances of synonym replacement.\n",
      "191870 instances of no synonym replacement.\n",
      "29805 instances of shuffling.\n",
      "29968 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#Chinese\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train_lwtr.conll') as f:\n",
    "    file = f.readlines()\n",
    "zh_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ZH-Chinese/wiki.zh/wiki.zh.bin')\n",
    "\n",
    "zh_mr = mr(file = zh_sr)\n",
    "\n",
    "all_methods = shuffle(file = zh_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "breathing-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28573 instances of shuffling.\n",
      "28285 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "#German\n",
    "with open('SemEval2022-Task11_Train-Dev/DE-German/de_train_sr.conll') as f:\n",
    "    file = [i for i in f.readlines()]\n",
    "de_lwtr = lwtr(train_file = file)\n",
    "\n",
    "de_mr = mr(file = de_lwtr)\n",
    "\n",
    "all_methods = shuffle(file = de_mr)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/DE-German/de_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-medicaid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train.conll') as f:\n",
    "    file = f.readlines()\n",
    "zh_sr = syn_replace(file, 'SemEval2022-Task11_Train-Dev/ZH-Chinese/wiki.zh/wiki.zh.bin')\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train_sr.conll', 'w') as file:\n",
    "    for line in zh_sr:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cleared-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/DE-German/de_train_sr.conll') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "powered-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in file:\n",
    "    if not i.startswith('# id ') and i.strip():\n",
    "        a.append(i.split(' _ _ ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "organized-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "lightweight-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CORP\\n',\n",
       " 'B-CW\\n',\n",
       " 'B-GRP\\n',\n",
       " 'B-LOC\\n',\n",
       " 'B-PER\\n',\n",
       " 'B-PROD\\n',\n",
       " 'I-CORP\\n',\n",
       " 'I-CW\\n',\n",
       " 'I-GRP\\n',\n",
       " 'I-LOC\\n',\n",
       " 'I-PER\\n',\n",
       " 'I-PROD\\n',\n",
       " 'O\\n'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-definition",
   "metadata": {},
   "source": [
    "# MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impressed-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr(file):\n",
    "    ############## DATA STRUCTURES SETUP ###############\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    mention_rep = defaultdict(list) #create default dictionary of lists\n",
    "    entities = ['PER', 'LOC', 'GRP', 'CORP', 'PROD', 'CW'] #all basic NER labels\n",
    "\n",
    "    begin = False #variable for when you've first encountered and captured the head of a mention (B-)\n",
    "    inside = False #variable for when you're inside the mention (I-). There can be 1+ of these\n",
    "\n",
    "    for entity in entities: #traverse through the entities\n",
    "        for line in file: #traverse through each line of the language file\n",
    "            if begin: #check to see if you've already run into the head of the mention\n",
    "                if f'I-{entity}' in line: #if not, then see if the I- is in this line\n",
    "                    temp_list.append(line) #if so, you must've gone to the 'elif' below and created the temp_list varible. Append current I- onto this list\n",
    "                    inside = True #switch to True to alert that you're inside the mention from now on\n",
    "\n",
    "                else: #if there's no I- in this line that means you've 1) got the head, and 2) either gotten all I-'s already or there's no more I-'s, and you're done trying to capture a mention\n",
    "                    if mention_rep[entity]: #check to see if you're already started storing values into this entity (PER, LOC, etc.)\n",
    "                        mention_rep[entity].append(temp_list) #if so, simply append the temp_list onto the existing list\n",
    "                    else: #if not that means this is your first entry for an entity's values. defaultdict(list) can't perform append when this happens...\n",
    "                        mention_rep[entity] = [temp_list] #...so we'll have to store the temp_list as a list to prevent the temp_list's contents from being broken into individual values and stored into the dict's value list\n",
    "                    begin = False #revert begin to False for next loop\n",
    "                    inside = False #revert inside for the same reason\n",
    "\n",
    "            elif f'B-{entity}' in line: #if you haven't already run into the head of the mention (B-), check to see if it's in this current loop/line\n",
    "                temp_list = [] #create a temporary list that you'll use to collect a mention's beginning (B-) and insides (I-). this will also reset the temp_list for subsequent loops \n",
    "                temp_list.append(line) #add the beginning labels (B-) to this list\n",
    "                begin = True #switch to True to alert that you've found the head label\n",
    "\n",
    "    #assert every mention was stored as a list\n",
    "    for i in mention_rep: #traverse the dict's keys\n",
    "        for j in mention_rep[i]: #traverse each value in the value-list of the key\n",
    "            assert type(j) is list #check if every value is a list. this is to ensure consistency later on\n",
    "\n",
    "\n",
    "    ################################################# PERFORM MENTION REPLACEMENT ########################################################\n",
    "    import numpy as np #will need ndarray\n",
    "\n",
    "    mr_file = []\n",
    "    labels = tuple(mention_rep.keys()) #set of labels: PER, LOC, GRP, CORP, PROD, CW\n",
    "\n",
    "    #capture_inside = False\n",
    "    for index, line in enumerate(file): #traverse through file by line\n",
    "        #print('line:', line)\n",
    "        if line.strip().endswith(labels): #endswith() is to filter out anything other than mentions\n",
    "            if line.strip().split(' _ _ ')[1].startswith('B'): #only get the beginnings of mentions (B-)\n",
    "                #print('is label')\n",
    "                x = random.binomial(n = 1, p = 0.5, size = 1) #randomizer. x will be 0 or 1\n",
    "                #print(f'x = {x}')\n",
    "                if x == 1: #x==1 means successfully random, perform mention replacement\n",
    "                    curr_label = line.split(' _ _ ')[1].strip()[2:] #current label type will be used as key next. '2:' is to remove the 'B-' or 'I-' from beginning of label\n",
    "                    #print(f'curr_label: {curr_label}')\n",
    "                    new_mention = np.random.choice(np.array(mention_rep[curr_label], dtype = 'object')) #have to make this ndarray because the values of our mention_rep[key] dictionary is lists of LISTS. it becomes deprecated. same logic applies as LwTR above\n",
    "                    #print(f'new_mention: {new_mention}')\n",
    "                    if len(new_mention) == 1: #just insert sole element\n",
    "                        #print('len 1')\n",
    "                        mr_file.append(new_mention[0])\n",
    "                        #print(f'{index+1}: {mr_file}')\n",
    "                    else: #multi-word mention\n",
    "                        #print('multi-word')\n",
    "                        for mention in new_mention: #traverse through new_mention list\n",
    "                            #test_file.insert(index+idx, mention) #subsequently insert each part of new_mention \n",
    "                            mr_file.append(mention)\n",
    "                            #print(f'{index+1}: {mr_file}\\n')\n",
    "                else: #B-, but no data augmentation\n",
    "                    #print('label, but no data augmentation')\n",
    "                    mr_file.append(line) #add line (non-replaced mention beginning (B-))\n",
    "                    capture_inside = True #this will enable capturing the inside (I-) of the mention if it appears next, instead of disregarding it\n",
    "                    #print(f'{index+1}: {mr_file}\\n')\n",
    "            elif capture_inside: #add the inside of mention, because we just had a non-replaced mention beginning (B-), so we must capture all insides of original mention\n",
    "                #print('unsuccessful mention replacement. capturing current inside mention, I-')\n",
    "                mr_file.append(line) #append non mention replaced inside (I-)\n",
    "                #print(f'{index+1}: {mr_file}\\n')\n",
    "    #         else:\n",
    "    #             print('sucessful mention replacement. not capturing current inside of mention')\n",
    "\n",
    "        else: #everything that doesn't have a mention label in it\n",
    "            #print('not label')\n",
    "            mr_file.append(line) #append current line\n",
    "            #print(f'{index+1}: {mr_file}\\n')\n",
    "            capture_inside = False #switch off the flag to indicate we must capture a mention inside\n",
    "\n",
    "\n",
    "    ############################################################### CHECKING ############################################################\n",
    "    new_count = 0\n",
    "    for i in mr_file:\n",
    "        if i.startswith('# id '):\n",
    "            new_count += 1\n",
    "    assert new_count == 15300\n",
    "    \n",
    "    return mr_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "respiratory-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "part3 = mr(file = a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-documentary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "concerned-morrison",
   "metadata": {},
   "source": [
    "# SiS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acute-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are as follows\n",
    "# PER : Person\n",
    "# LOC : Location\n",
    "# GRP : Group\n",
    "# CORP : Corporation\n",
    "# PROD : Product\n",
    "# CW: Creative Work\n",
    "# O: out-of-mention label (i.e. unrelated to named entity)\n",
    "\n",
    "# B - beginning of label, I - inside label\n",
    "from numpy import random\n",
    "\n",
    "def shuffle(file):\n",
    "    labels = tuple(['-PER\\n', '-LOC\\n', '-GRP\\n', '-CORP\\n', '-PROD\\n', '-CW\\n', ' _ _ O']) #set of labels: PER, LOC, GRP, CORP, PROD, CW, and O\n",
    "    shuffle_file = []\n",
    "    prev_label = None\n",
    "    temp_list = []\n",
    "    shuffle_count = 0\n",
    "    non_shuffle_count = 0\n",
    "    \n",
    "    for index, line in enumerate(file):\n",
    "        #print(f'Loop: {index+1} current line: {line} temp_list: {temp_list}')\n",
    "        #print(f'shuffle_file: {shuffle_file}')\n",
    "        if not line.startswith('# id ') and line.strip(): #to filter out #id's and \\n\n",
    "            for label in labels:\n",
    "                if label in line:\n",
    "                    curr_label = label\n",
    "                    break\n",
    "                    \n",
    "            if curr_label != prev_label and temp_list: #when you've come to a new label, and not on your first loop\n",
    "                x = random.binomial(n=1, p=0.5, size=1)\n",
    "                if x == 1: #perform shuffle data augmnetation\n",
    "                    temp_label = [line.split(' _ _ ')[1] for line in temp_list]\n",
    "                    random.shuffle(temp_list)\n",
    "                    #print('data not augmenting')\n",
    "                    #print(f'temp_list before looping through: {temp_list}')\n",
    "                    for index, shuff_line in enumerate(temp_list): #traverse through temp list\n",
    "                        shuffle_file.append(shuff_line.split(' _ _ ')[0] + ' _ _ ' + temp_label[index]) #putting labels in their original label\n",
    "                    temp_list.clear() #reset temp_list\n",
    "                    temp_list.append(line) #begin new temp_list with current new label\n",
    "                    prev_label = curr_label #reassign current label value to prev_label to be used as reference for next loop\n",
    "                    shuffle_count += 1\n",
    "                    #print('data augmenting')\n",
    "                    #print(f'after new temp_list: {temp_list}')\n",
    "                else: #don't shuffle, just append\n",
    "                    #print('data not augmenting')\n",
    "                    #print(f'temp_list before looping through: {temp_list}')\n",
    "                    for original_line in temp_list:\n",
    "                        shuffle_file.append(original_line)\n",
    "                    temp_list.clear() #reset temp_list\n",
    "                    temp_list.append(line) #begin new temp_list with current new label\n",
    "                    prev_label = curr_label #reassign current label value to prev_label to be used as reference for next loop\n",
    "                    non_shuffle_count += 1\n",
    "                    #print('data not augmenting')\n",
    "                    #print(f'after new temp_list: {temp_list}')\n",
    "                #temp_list.append(line)\n",
    "            else: #not on transitionary label. this could mean you're on your first label or another of the same label you've been on\n",
    "                temp_list.append(line) #add current line to temp_list\n",
    "                #print(f'{index+1} {line} prev_label: {prev_label}')\n",
    "                prev_label = curr_label #reassign current label value to prev_label to be used as reference for next loop\n",
    "                #print(f'{index+1} {line} curr_label: {curr_label}')\n",
    "        elif line == '\\n': #end of current #id NER, shuffle and dump current temp_list holdings\n",
    "            x = random.binomial(n=1, p=0.5, size=1)\n",
    "            if x == 1: #perform shuffle data augmnetation\n",
    "                temp_label = [line.split(' _ _ ')[1] for line in temp_list] #retain labels in order\n",
    "                random.shuffle(temp_list)\n",
    "                #print('data not augmenting')\n",
    "                #print(f'temp_list before looping through: {temp_list}')\n",
    "                for index, shuff_line in enumerate(temp_list): #traverse through temp list\n",
    "                        shuffle_file.append(shuff_line.split(' _ _ ')[0] + ' _ _ ' + temp_label[index]) #putting labels in their original label\n",
    "                shuffle_file.append(line)\n",
    "                temp_list.clear() #reset temp_list\n",
    "                prev_label = None #reassign current label value to prev_label to be used as reference for next loop\n",
    "                shuffle_count += 1\n",
    "                #print('data augmenting')\n",
    "                #print(f'after new temp_list: {temp_list}')\n",
    "            else: #don't shuffle, just append\n",
    "                #print('data not augmenting')\n",
    "                #print(f'temp_list before looping through: {temp_list}')\n",
    "                for original_line in temp_list:\n",
    "                    shuffle_file.append(original_line)\n",
    "                shuffle_file.append(line)\n",
    "                temp_list.clear() #reset temp_list\n",
    "                prev_label = None #reassig\n",
    "                non_shuffle_count += 1\n",
    "        else:\n",
    "            shuffle_file.append(line) #append #id's and \\n\n",
    "            prev_label = None\n",
    "    print(f'{shuffle_count} instances of shuffling.')\n",
    "    print(f'{non_shuffle_count} instances of not shuffling.')\n",
    "    return shuffle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "together-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29500 instances of shuffling.\n",
      "29590 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "all_methods = shuffle(file = part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "robust-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29877 instances of shuffling.\n",
      "29896 instances of not shuffling.\n"
     ]
    }
   ],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train.conll') as f:\n",
    "    en_test = f.readlines()\n",
    "testing = shuffle(file = en_test)\n",
    "\n",
    "with open('SemEval2022-Task11_Train-Dev/ZH-Chinese/zh_train_sis.conll', 'w') as file:\n",
    "    for line in testing:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conceptual-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SemEval2022-Task11_Train-Dev/EN-English/en_train_all.conll', 'w') as file:\n",
    "    for line in all_methods:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-asian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
